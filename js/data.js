/**
 * js/data.js
 * Central data source for both the main index.html (Project List) and individual Project Pages.
 */

const publicationsData = [
  // --- 2025 ---
  {
    id: 'p19',
    showInList: true,
    title: "Understanding Freehand Cursorless Pointing Variability and Its Impact on Selection Performance",
    authors: "James Whiffing, Tobias Langlotz, Christof Lutteroth, Adwait Sharma, Christopher Clarke",
    venue: "TOCHI 2025",
    type: ["Journal", "Interaction Techniques"],
    desc: "Systematically characterised and described three distinct pointing behaviours, each with three different traits, ranging from accurate stereotypical pointing observed in prior works to more casual hip fire-style pointing.",
    fullAbstract: "Freehand pointing is a fundamental gesture commonly used for cursorless interactions. Prior work in HCI often elicits the same pointing behaviour – facing the target with an outstretched dominant arm and index finger. However, freehand pointing outside of HCI shows more variability across hand pose, usage, and coordination with gaze. To understand what variability exists and how it affects pointing performance, we collected data (N=23) using a hybrid motion capture system. To elicit a wide variety of pointing behaviours we included different levels of user effort and attention, as well as the widest range of target placements studied. We systematically characterised and described three distinct pointing behaviours, each with three different traits, ranging from accurate stereotypical pointing observed in prior works to more casual hip fire-style pointing. Our analysis demonstrates how different pointing behaviours affect pointing performance and highlights their importance when designing interactive systems for more naturalistic freehand pointing.",
    thumb: "images/publications/pointing_tochi25.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3770583",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@article{10.1145/3770583,
  author = {Whiffing, James and Langlotz, Tobias and Lutteroth, Christof and Sharma, Adwait and Clarke, Christopher},
  title = {Understanding Freehand Cursorless Pointing Variability and Its Impact on Selection Performance},
  year = {2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  issn = {1073-0516},
  url = {https://doi.org/10.1145/3770583},
  doi = {10.1145/3770583},
  note = {Just Accepted},
  journal = {ACM Trans. Comput.-Hum. Interact.},
  month = oct,
  keywords = {Cursorless, Freehand, Pointing, Interaction Techniques, Gesture}
}
`},
  {
    id: 'p18',
    showInList: true,
    title: "GraspR: A Computational Model of Spatial User Preferences for Adaptive Grasp UI Design",
    authors: "Arthur Caetano, Yunhao Luo, Adwait Sharma, Misha Sra",
    venue: "UIST 2025",
    type: ["Conference", "AI & Computational Design", "Interaction Techniques"],
    desc: "Computational model that predicts user preferences for single-finger microgestures in GraspUIs.",
    fullAbstract: "Grasp User Interfaces (grasp UIs) enable dual-tasking in XR by allowing interaction with digital content while holding physical objects. However, current grasp UI design practices face a fundamental challenge: existing approaches either capture user preferences through labor-intensive elicitation studies that are difficult to scale, or rely on biomechanical models that overlook subjective factors. We introduce GraspR, the first computational model that predicts user preferences for single-finger microgestures in grasp UIs. Our data-driven approach combines the scalability of computational methods with human preference modeling, trained on 1,520 preferences collected via a two-alternative forced choice paradigm across eight participants and four frequently used grasp variations. We demonstrate GraspR’s effectiveness through a working prototype that dynamically adjusts interface layouts across four everyday tasks. We release both the dataset and code to support future research in adaptive grasp UIs.",
    thumb: "images/publications/graspr_uist25.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3746059.3747744",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://www.youtube.com/watch?v=5khyDJbCbAE",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3746059.3747744,
  author = {Caetano, Arthur and Luo, Yunhao and Sharma, Adwait and Sra, Misha},
  title = {GraspR: A Computational Model of Spatial User Preferences for Adaptive Grasp UI Design},
  year = {2025},
  isbn = {9798400720376},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3746059.3747744},
  doi = {10.1145/3746059.3747744},
  booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {96},
  numpages = {16},
  keywords = {grasp-based interfaces, user preference, adaptive interfaces, extended reality},
  location = {
},
  series = {UIST '25}
}`
  },
  {
    id: 'p17',
    showInList: true,
    title: "HydroHaptics: High-Fidelity Force-Feedback on Soft Deformable Interfaces using Hydrostatic Transmission",
    authors: "James Nash, Kim Sauvé, Catharina Maria van Riet, Anke van Oosterhout, Adwait Sharma, Christopher Clarke, Jason Alexander",
    venue: "UIST 2025",
    type: ["Conference", "Interaction Techniques", "Sensing"],
    desc: "Platform that enables high-fidelity force feedback on deformable interfaces via hydrostatic transmission.",
    fullAbstract: "Soft deformable interfaces offer unique interaction potential through input flexibility and diverse forms. However, force feedback on these devices remains limited, with pneumatic approaches lacking responsiveness and precision, while microhydraulic solutions are constrained to small form factors with limited input. We present HydroHaptics, a novel platform that enables high-fidelity force feedback on deformable interfaces via hydrostatic transmission. Surpassing current state-of-the-art methods, our approach allows fine-grained force feedback on soft interfaces, achieving a 10 N force change in <  100 ms and accurate 1 N, 10 Hz oscillation rendering. We detail the system’s design and implementation, highlighting its ability to maintain the inherent interaction benefits of soft interfaces. A user study (N = 18) evaluates the system’s performance, showing high accuracy in rendering distinct haptic effects (82.6% accuracy) and classifying input gestures (89.1% accuracy). To showcase the platform’s versatility, we present four applications illustrating HydroHaptics’ potential to enhance interaction with deformable devices and unlock novel user experiences.",
    thumb: "images/publications/hydrohaptics_uist25.webp",
    modalVideo: "",
    award: '<span class="pub-award"><i class="fa-solid fa-trophy"></i> Best Paper Honorable Mention</span>',
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3746059.3747679",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://www.youtube.com/watch?v=t_WbTRO7eic",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3746059.3747679,
  author = {Nash, James and Sauv\'{e}, Kim and van Riet, Catharina Maria and van Oosterhout, Anke and Sharma, Adwait and Clarke, Christopher and Alexander, Jason},
  title = {HydroHaptics: High-Fidelity Force-Feedback on Soft Deformable Interfaces using Hydrostatic Transmission},
  year = {2025},
  isbn = {9798400720376},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3746059.3747679},
  doi = {10.1145/3746059.3747679},
  booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {59},
  numpages = {20},
  keywords = {Deformable interfaces, Haptics, Non-rigid interactions, Tangible Interactions, Force Feedback},
  location = {
},
  series = {UIST '25}
}`
  },
  {
    id: 'p16',
    showInList: true,
    title: "SparseEMG: Computational Design of Sparse EMG Layouts for Sensing Gestures",
    authors: "Anand Kumar, Antony Albert Raj Irudayaraj, Ishita Chandra, Adwait Sharma, Aditya Shekhar Nittala",
    venue: "UIST 2025",
    type: ["Conference", "Sensing", "AI & Computational Design", "Interaction Techniques"],
    desc: "Computational tool designed for rapid prototyping of sparse EMG electrode layouts for gesture recognition.",
    fullAbstract: "Gesture recognition with electromyography (EMG) is a complex problem influenced by gesture sets, electrode count and placement, and machine learning parameters (e.g., features, classifiers). Most existing toolkits focus on streamlining model development but overlook the impact of electrode selection on classification accuracy. In this work, we present the first data-driven analysis of how electrode selection and classifier choice affect both accuracy and sparsity. Through a systematic evaluation of 28 combinations (4 selection schemes, 7 classifiers), across six datasets, we identify an approach that minimizes electrode count without compromising accuracy. The results show that Permutation Importance (selection scheme) with Random Forest (classifier) reduces the number of electrodes by 53.5%. Based on these findings, we introduce SparseEMG, a design tool that generates sparse electrode layouts based on user-selected gesture sets, electrode constraints, and ML parameters while also predicting classification performance. SparseEMG supports 50+ unique gestures and is validated in three real-world applications using different hardware setups. Results from our multi-dataset evaluation show that the layouts generated from the SparseEMG design tool are transferable across users with only minimal variation in gesture recognition performance.",
    thumb: "images/publications/sparseemg_uist25.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3746059.3747679",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://youtu.be/Glz_zT70TPc?si=LDBbB3VOuYuvH5jY",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3746059.3747614,
  author = {Kumar, Anand and Irudayaraj, Antony Albert Raj and Chandra, Ishita and Sharma, Adwait and Nittala, Aditya Shekhar},
  title = {SparseEMG: Computational Design of Sparse EMG Layouts for Sensing Gestures},
  year = {2025},
  isbn = {9798400720376},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3746059.3747614},
  doi = {10.1145/3746059.3747614},
  booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {193},
  numpages = {20},
  keywords = {Electromyography, Gesture Recognition, Design tools},
  location = {
},
  series = {UIST '25}
}
`
  },
  {
    id: 'p15',
    showInList: true,
    title: "Investigating the Impact of Deformable, Movable, and Rigid Surfaces on Force-Input Interactions",
    authors: "James Nash, Kim Sauvé, Adwait Sharma, Christopher Clarke, Jason Alexander",
    venue: "TOCHI 2025",
    type: ["Journal", "Interaction Techniques"],
    desc: "A comprehensive study on how deformable, movable, and rigid surface properties affect force-based input performance.",
    fullAbstract: "The force modality fundamentally transforms the interaction space of traditional touch input. When paired with compliant devices, which deform under force and provide immediate haptic feedback, there is potential to enhance user interactions significantly. However, the effects of compliance on force-input remain under-explored, with limited understanding of their full potential. This article presents the first systematic investigation of the impact of deformable, movable, and rigid surfaces on user performance and experience through three rigorous studies (each N = 28). The results reveal previously unreported effects, including (1) higher maximum comfortable forces on deformable surfaces, (2) user preference for soft and deformable surfaces over rigid surfaces, and (3) improved ability to maintain force input on softer surfaces. These results highlight the benefits of compliant surfaces, contrasting with the dominant use of force-input on rigid devices. These findings guide researchers and designers in optimizing user experience and performance of force-input interactions.",
    thumb: "images/publications/force_tochi25.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3736409",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@article{10.1145/3736409,
  author = {Nash, James and Sauv\'{e}, Kim and Sharma, Adwait and Clarke, Christopher and Alexander, Jason},
  title = {Investigating the Impact of Deformable, Movable, and Rigid&nbsp;Surfaces on Force-Input Interactions},
  year = {2025},
  issue_date = {October 2025},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {32},
  number = {5},
  issn = {1073-0516},
  url = {https://doi.org/10.1145/3736409},
  doi = {10.1145/3736409},
  journal = {ACM Trans. Comput.-Hum. Interact.},
  month = oct,
  articleno = {44},
  numpages = {57},
  keywords = {Force Input, Non-Rigid Interactions, Deformable, Movable, User Study, Soft Surfaces, Pressure Input}
}`
  },
  {
    id: 'p14', // Note: This ID 'p14' maps to 'project-pages/p14.html'
    showInList: true,
    title: "Beyond Vacuuming: How Can We Exploit Domestic Robots’ Idle Time?",
    authors: "Yoshiaki Shiokawa, Winnie Chen, Aditya Shekhar Nittala, Jason Alexander, Adwait Sharma",
    venue: "CHI 2025",
    type: ["Conference", "Robotics", "Interaction Techniques"],
    award: '<span class="pub-award"><i class="fa-solid fa-newspaper"></i> Covered by 100+ Media Outlets</span>',
    desc: "Reappropriating idle domestic robots for ubiquitous computing, providing over 100 use cases and a design space.",
    fullAbstract: "We are increasingly adopting domestic robots (e.g., Roomba) that provide relief from mundane household tasks. However, these robots usually only spend little time executing their specific task and remain idle for long periods. They typically possess advanced mobility and sensing capabilities, and therefore have significant potential applications beyond their designed use. Our work explores this untapped potential of domestic robots in ubiquitous computing, focusing on how they can improve and support modern lifestyles. We conducted two studies: an online survey (n=50) to understand current usage patterns of these robots within homes and an exploratory study (n=12) with HCI and HRI experts. Our thematic analysis revealed 12 key dimensions for developing interactions with domestic robots and outlined over 100 use cases, illustrating how these robots can offer proactive assistance and provide privacy. Finally, we implemented a proof-of-concept prototype to demonstrate the feasibility of reappropriating domestic robots for diverse ubiquitous computing applications.",
    thumb: "images/beyond-vacuuming-featured.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3706598.3714266",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://www.youtube.com/watch?v=otZGk7nC-ZE",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3706598.3714266,
  author = {Shiokawa, Yoshiaki and Chen, Winnie and Nittala, Aditya Shekhar and Alexander, Jason and Sharma, Adwait},
  title = {Beyond Vacuuming: How Can We Exploit Domestic Robots' Idle Time?},
  year = {2025},
  isbn = {9798400713941},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3706598.3714266},
  doi = {10.1145/3706598.3714266},
  booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  articleno = {733},
  numpages = {17},
  keywords = {domestic robots, ubiquitous, interaction, design space},
  location = {
},
  series = {CHI '25}
}`
  },

  // --- 2024 ---
  {
    id: 'p13',
    showInList: true,
    title: "Initial Exploration into Electrotactile Tongue Stimulation for Providing Force Feedback for Robot-Assisted Surgery",
    authors: "Dinmukhammed Mukashev, Agnieszka Lach, Chet W Hammill, Zhanat Kappassov, Adwait Sharma, Aditya Shekhar Nittala, Luv Kohli, Sharif Razzaque",
    venue: "BSN 2024",
    type: ["Conference", "Interaction Techniques", "Robotics", "Sensing"],
    desc: "Investigation electrotactile tongue stimulation as a low-latency, mechanically simple method for providing force feedback.",
    fullAbstract: "We report findings from initial exploration into using electrotactile stimulation, on the surgeon's tongue, as a potential lower-latency and less mechanically-complex way to provide force-feedback to the operator of robot-assisted surgery. We conducted a pilot feasibility study wherein participants attempted to teleoperate a robot to grasp and lift chicken eggs without breaking or dropping them. The force measured by the robot's gripper was displayed differently based on the experimental condition: visually only, or visually with electrotactile tongue stimulation. Participants were more successful lifting eggs with tongue stimulation. Data from this preliminary study, along with insights from informal interviews, suggest that tongue stimulation has potential to enhance the efficacy and safety of robot-assisted surgery.",
    thumb: "images/publications/electrotactile_bsn24.webp",
    modalVideo: "",
    pdf: "https://ieeexplore.ieee.org/document/10780705",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@INPROCEEDINGS{10780705,
  author= {Mukashev, Dinmukhammed and Lach, Agnieszka and Hammill, Chet W and Kappassov, Zhanat and Sharma, Adwait and Nittala, Aditya Shekhar and Kohli, Luv and Razzaque, Sharif},
  booktitle= {2024 IEEE 20th International Conference on Body Sensor Networks (BSN)},
  title= {Initial Exploration into Electrotactile Tongue Stimulation for Providing Force Feedback for Robot-Assisted Surgery},
  year= {2024},
  volume= {},
  number= {},
  pages= {1-4},
  keywords= {Electric potential;Tongue;Force measurement;Force feedback;Surgery;Particle measurements;Safety;Interviews;Grippers;Robots;haptics;force feedback;robotic-assisted surgery;displays;tongue;sensory substitution;electrotactile stimulation},
  doi= {10.1109/BSN63547.2024.10780705}
}

}
`
  },


  {
    id: 'p12',
    showInList: true,
    title: "Accelerating XR Innovation through a pan-European Lab Network: An Overview of the EMIL Project",
    authors: "Justus Blönnigen, Christopher Clarke, Andreas Dahn, Lisa Forelli, Ramyah Gowrishankar, Tuija Heikura, Volker Helzle, Paul Hine, Crescent Jicol, Alexander Kreische, Elisa Macedo Lopes, David Maillard, João Marques, Christoph Mathis, Alina-Maria Moldovan, Jan Müller, Louis Nisiotis, Yiannos Panteli, Bart Rienties, Adwait Sharma, Neil Thomson, Zsolt Wilhelm, Aseel Yahya, José-Alberto Zurdo Urbano",
    venue: "IMX Workshop 2024",
    type: ["Conference", "Interaction Techniques"],
    desc: "Pan-European network of XR labs to accelerate the development of AR/VR/MR technologies and content through funding and collaboration opportunities.",
    fullAbstract: "European Media and Immersion Lab, or EMIL, is a pan-European network of extended reality (XR) labs consisting of 4 European academic institutions, with a mission to accelerate development of virtual, augmented and mixed reality technologies, content, services and applications. The 30-month project, which started in September 2022, has been funded by the European Union and co-funded by Innovate UK. This paper gives an overview of the project’s goals, its organization, and selected results that have been achieved.",
    thumb: "images/publications/emil_imx24.webp",
    modalVideo: "",
    pdf: "#",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3672406.3672426,
  author = {Bl\"{o}nnigen, Justus and Clarke, Christopher and Dahn, Andreas and Forelli, Lisa and Gowrishankar, Ramyah and Heikura, Tuija and Helzle, Volker and Hine, Paul and Jicol, Crescent and Kreische, Alexander and Lutteroth, Christof and Mac\'{\i}a, Francisco and Moesgen, Tim and Pares, Narcis and Plichta, Leszek and Potts, Dominic and Sch\"{a}fer, Eduard and Sharma, Adwait and Spielmann, Simon and Tenhunen, Juhani and Trottnow, Jonas and Tseng, Yu-Han and Vikberg, Esa and Xiao, Yu},
  title = {Accelerating XR Innovation through a pan-European Lab Network: An overview of the EMIL project},
  year = {2024},
  isbn = {9798400717949},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3672406.3672426},
  doi = {10.1145/3672406.3672426},
  booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences Workshops},
  pages = {137–141},
  numpages = {5},
  keywords = {Extended reality, FSTP, immersive media},
  location = {Stockholm, Sweden},
  series = {IMXw '24}
}

`
  },



  {
    id: 'p11',
    showInList: true,
    title: "GraspUI: Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping",
    authors: "Adwait Sharma, Alexander Ivanov, Frances Lai, Tovi Grossman, Stephanie Santosa",
    venue: "DIS 2024",
    type: ["Conference", "Interaction Techniques"],
    desc: "Design space for object-centric microgesture interactions throughout the grasping process.",
    fullAbstract: "Objects are indispensable tools in our daily lives. Recent research has demonstrated their potential to act as conduits for digital interactions with microgestures, however, the primary focus was on situations where the hand firmly grasps an object. We introduce GraspUI, an exploratory design space of object-centric gestures within the seven distinct phases of the grasping process, spanning pre-, during, and post-grasp movements. We conducted ideation sessions with mixed-reality designers from industry and academia to explore gesture integration throughout the entire grasping process. The outcome was 38 storyboards envisioning practical applications. To evaluate the design space’s utility, we performed a video-based assessment with end-users. We then implemented an interactive prototype and quantified the overhead cost of performing proposed gestures through a secondary study. Participants reacted positively to gestures and could integrate them into existing usage of objects. To conclude, we highlight technical and usability guidelines for implementing and extending GraspUI systems.",
    thumb: "images/graspui-featured.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3643834.3661551",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://www.youtube.com/watch?v=KriAYkbvj28",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3643834.3661551,
  author = {Sharma, Adwait and Ivanov, Alexander and Lai, Frances and Grossman, Tovi and Santosa, Stephanie},
  title = {GraspUI: Seamlessly Integrating Object-Centric Gestures within the Seven Phases of Grasping},
  year = {2024},
  isbn = {9798400705830},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3643834.3661551},
  doi = {10.1145/3643834.3661551},
  booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
  pages = {1275–1289},
  numpages = {15},
  keywords = {design space, everyday objects, grasp, grasping process, hand-object manipulation, input},
  location = {Copenhagen, Denmark},
  series = {DIS '24}
}

`
  },
  {
    id: 'p10',
    showInList: true,
    title: "SeamSleeve: Robust Arm Movement Sensing through Powered Stitching",
    authors: "Olivia G Ruston, Adwait Sharma, Mike Fraser",
    venue: "DIS 2024",
    type: ["Conference", "Sensing", "Interaction Techniques"],
    desc: "Minimally invasive e-textile design that uses clothing seams as sensors for tracking arm movements.",
    fullAbstract: "Despite significant advances in interactive clothing over the past decade, e-textiles lack traditional fabric robustness and comfort. SeamSleeve provides a method for using garment seams as sensing channels while retaining the benefits of regular clothing design. We power conductive seams at low voltages to stitch together everyday fabric panels, resulting in a novel sensing mechanism capable of detecting arm movements. Our first empirical study (n=10) identifies optimal seam design and placement on the sleeve, by comparing traditional seam forms in the context of sensing capabilities. A second study (n=14) demonstrates that our minimal sensing approach is capable of successfully classifying 8 arm exercises with an accuracy of 84%. Our findings support the effectiveness of the approach in areas such as longitudinal physiotherapeutic rehabilitation beyond the clinic, enabling everyday motion capture.",
    thumb: "images/publications/seamsleeve_dis24.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3643834.3660726",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3643834.3660726,
  author = {Ruston, Olivia G and Sharma, Adwait and Fraser, Mike},
  title = {SeamSleeve: Robust Arm Movement Sensing through Powered Stitching},
  year = {2024},
  isbn = {9798400705830},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3643834.3660726},
  doi = {10.1145/3643834.3660726},
  booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
  pages = {1134–1147},
  numpages = {14},
  keywords = {conductive stitching, e-textiles, everyday movement tracking, interactive garments},
  location = {Copenhagen, Denmark},
  series = {DIS '24}
}

`
  },

  {
    id: 'p9',
    showInList: true,
    title: "Emotion-Aware In-Car Feedback: A Comparative Study",
    authors: "Kevin Fred Mwaita, Rahul Bhaumik, Aftab Ahmed, Adwait Sharma, Antonella De Angeli, Michael Haller",
    venue: "MTI 2024",
    type: ["Journal", "Interaction Techniques", "Sensing", "AI & Computational Design"],
    desc: "Personalized in-car feedback design guidelines developed by evaluating the impact of different feedback modalities on driver emotions and preferences.",
    fullAbstract: "We investigate personalised feedback mechanisms to help drivers regulate their emotions, aiming to improve road safety. We systematically evaluate driver-preferred feedback modalities and their impact on emotional states. Using unobtrusive vision-based emotion detection and self-labeling, we captured the emotional states and feedback preferences of 21 participants in a simulated driving environment. Results show that in-car feedback systems effectively influence drivers’ emotional states, with participants reporting positive experiences and varying preferences based on their emotions. We also developed a machine learning classification system using facial marker data to demonstrate the feasibility of our approach for classifying emotional states. Our contributions include design guidelines for tailored feedback systems, a systematic analysis of user reactions across three feedback channels with variations, an emotion classification system, and a dataset with labeled face landmark annotations for future research.",
    thumb: "images/publications/emocar_mti24.webp",
    modalVideo: "",
    pdf: "https://www.mdpi.com/2414-4088/8/7/54",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `
@Article{mti8070054,
  AUTHOR = {Mwaita, Kevin Fred and Bhaumik, Rahul and Ahmed, Aftab and Sharma, Adwait and De Angeli, Antonella and Haller, Michael},
  TITLE = {Emotion-Aware In-Car Feedback: A Comparative Study},
  JOURNAL = {Multimodal Technologies and Interaction},
  VOLUME = {8},
  YEAR = {2024},
  NUMBER = {7},
  ARTICLE-NUMBER = {54},
  URL = {https://www.mdpi.com/2414-4088/8/7/54},
  ISSN = {2414-4088},
  DOI = {10.3390/mti8070054}
}
`
  },


  {
    id: 'p8',
    showInList: true,
    title: "DeformIO: Dynamic Stiffness Control on a Deformable Force-sensing Display",
    authors: "James David Nash, Cameron Steer, Teodora Dinca, Adwait Sharma, Alvaro Favaratto Santos, Benjamin Timothy Wildgoose, Alexander Ager, Christopher Clarke, Jason Alexander",
    venue: "CHI EA 2024",
    type: ["Conference", "Interaction Techniques", "Sensing"],
    desc: "Deformable display that supports continuous force input and output, multi-touch interaction, and variable stiffness control.",
    fullAbstract: "Introducing DeformIO, a novel deformable display with co-located force input and variable stiffness output. Unlike prior work, our approach does not require pin arrays or re-configurable panels. Instead, we leveraged pneumatics and resistive sensing to enable force detection and stiffness control on a soft continuous surface. This allows users to perceive rich tactile feedback on a soft surface and replicates the benefits of fluid finger movement from traditional glass-based screens. Using a robotic arm, we conducted a series of evaluations with 3,267 trials to quantify the performance of touch and force input, as well as stiffness output. Additionally, our study confirmed users’ ability to apply multiple force inputs simultaneously and distinguish stiffness levels. We illustrate how DeformIO enhances interaction through a vision for everyday interaction and include two implemented self-contained demonstrations.",
    thumb: "images/publications/deformio_chiea24.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3613905.3650772",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://youtu.be/2lQo4Vu5CSU?si=Z-uJfh8zto-8xOYQ",
    // codeUrl: "https://youtu.be/bZZrjsYl7AQ?si=oGy-XwFrNSYfyLZj",
    bibtex: `@inproceedings{10.1145/3613905.3650772,
  author = {Nash, James David and Steer, Cameron and Dinca, Teodora and Sharma, Adwait and Favaratto Santos, Alvaro and Wildgoose, Benjamin Timothy and Ager, Alexander and Clarke, Christopher and Alexander, Jason},
  title = {DeformIO: Dynamic Stiffness Control on a Deformable Force-sensing Display},
  year = {2024},
  isbn = {9798400703317},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3613905.3650772},
  doi = {10.1145/3613905.3650772},
  booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
  articleno = {98},
  numpages = {8},
  keywords = {Deformable Display, Force Input, Pneumatics, Variable Stiffness},
  location = {Honolulu, HI, USA},
  series = {CHI EA '24}
}

`
  },


  {
    id: 'p7',
    showInList: true,
    title: "Pic2Tac: Creating Accessible Tactile Images using Semantic Information from Photographs",
    authors: "Karolina Pakenaite, Eirini Kamperou, Michael J Proulx, Adwait Sharma, Peter Hall",
    venue: "TEI 2024",
    type: ["Conference", "AI & Computational Design", "Interaction Techniques"],
    desc: "Cost-effective system using computer vision to convert photos into tactile images.",
    fullAbstract: "We introduce Pic2Tac, a novel system that automatically converts photographs into tactile images. It offers an alternative way to communicate visual information that is difficult to express using braille or alternative text. Current methods for creating tactile images are either limited in representation, or require handmade artefacts. Pic2Tac employs a unique approach that avoids a literal representation of image content (e.g. contours). Instead, it detects salient semantic content within photographs and translates them into tactile images using dedicated ‘tactile words’. Foreground objects are represented using icons, and patterns are used for background regions. The resulting binary image is printed on swell paper, where black regions rise to form a tactile image. Studies involving 60 participants, both sighted and with visual impairments, demonstrate the effectiveness of these tactile images in communicating semantic meaning. Our findings show that tactile and visual descriptions of scenes matched significantly. Overall, Pic2Tac is an affordable way to create accessible tactile images, costing only 1.50 USD per sheet.",
    thumb: "images/publications/pic2tac_tei24.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3623509.3633377",
    projectUrl: "#",
    slides: "#",
    videoUrl: "https://www.youtube.com/watch?v=Rn0kvs_s4fo",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3623509.3633377,
  author = {Pakenaite, Karolina and Kamperou, Eirini and Proulx, Michael J and Sharma, Adwait and Hall, Peter},
  title = {Pic2Tac: Creating Accessible Tactile Images using Semantic Information from Photographs},
  year = {2024},
  isbn = {9798400704024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3623509.3633377},
  doi = {10.1145/3623509.3633377},
  booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
  articleno = {29},
  numpages = {12},
  keywords = {Accessibility, Photographs, Semantic information, Tactile images},
  location = {Cork, Ireland},
  series = {TEI '24}
}

`
  },
  // --- 2023 ---

  {
    id: 'p6',
    showInList: true,
    title: "Design and Fabrication of Body-Based Interfaces (Demo of Saarland HCI Lab)",
    authors: "Jürgen Steimle, Marie Muehlhaus, Madalina Luciana Nicolae, Aditya Shekhar Nittala, Narjes Pourjafarian, Adwait Sharma, Marc Teyssier, Marion Koelle, Bruno Fruchard, Paul Strohmeier",
    venue: "CHI EA 2023",
    type: ["Conference", "Sensing", "Interaction Techniques"],
    award: '<span class="pub-award"><i class="fa-solid fa-trophy"></i> People\'s Choice Best Demo Award</span>',
    desc: "Live demonstrations of the lab’s recent work, shown to thousands of CHI \'23 conference attendees.",
    fullAbstract: "This Interactivity shows live demonstrations of our lab’s most recent work on body-based interfaces. The soft, curved and deformable surface of the human body presents unique opportunities and challenges for interfaces. New form factors, materials and interaction techniques are required that move past the conventional rigid, planar and rectangular devices and the corresponding interaction styles. We highlight three themes of challenges for soft body-based interfaces: 1) How to design interfaces that are optimized for the body? We demonstrate how interactive computational design tools can help novices and experts to create better device designs. 2) Once they are designed, how to physically prototype and fabricate soft interfaces? We show accessible DIY fabrication methods for soft devices made of functional materials that make use of biomaterials. 3) How to leverage the richness of interacting on the body? We demonstrate on-body and off-body interactions that leverage the soft properties of the interface.",
    thumb: "images/publications/demo_chi23.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3544549.3583916",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3544549.3583916,
  author = {Steimle, J\"{u}rgen and Muehlhaus, Marie and Nicolae, Madalina Luciana and Nittala, Aditya Shekhar and Pourjafarian, Narjes and Sharma, Adwait and Teyssier, Marc and Koelle, Marion and Fruchard, Bruno and Strohmeier, Paul},
  title = {Design and Fabrication of Body-Based Interfaces (Demo of Saarland HCI Lab)},
  year = {2023},
  isbn = {9781450394222},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3544549.3583916},
  doi = {10.1145/3544549.3583916},
  booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
  articleno = {446},
  numpages = {4},
  keywords = {On-body interaction, computational design, critical design., fabrication, new materials},
  location = {Hamburg, Germany},
  series = {CHI EA '23}
}

`
  },





  // --- 2022 ---

  {
    id: 'p5',
    showInList: true,
    title: "Design and Recognition of Microgestures for Always-Available Input",
    authors: "Adwait Sharma",
    venue: "PhD Thesis",
    type: ["Thesis", "Sensing", "Interaction Techniques", "AI & Computational Design"],
    desc: "Committee: Prof. Jürgen Steimle (Saarland University), Prof. Daniel Vogel (University of Waterloo), Prof. Antonio Krüger (German Research Center for Artificial Intelligence - DFKI), Dr. Alice Haynes (Saarland University)",
    fullAbstract: "Gestural user interfaces for computing devices most commonly require the user to have at least one hand free to interact with the device, for example, moving a mouse, touching a screen, or performing mid-air gestures. Consequently, users find it difficult to operate computing devices while holding or manipulating everyday objects. This limits the users from interacting with the digital world during a significant portion of their everyday activities, such as, using tools in the kitchen or workshop, carrying items, or workout with sports equipment. This thesis pushes the boundaries towards the bigger goal of enabling always-available input. Microgestures have been recognized for their potential to facilitate direct and subtle interactions. However, it remains an open question how to interact using gestures with computing devices when both of the user’s hands are occupied holding everyday objects. We take a holistic approach and focus on three core contributions: i) To understand end-users preferences, we present an empirical analysis of users’ choice of microgestures when holding objects of diverse geometries. Instead of designing a gesture set for a specific object or geometry and to identify gestures that generalize, this thesis leverages the taxonomy of grasp types established from prior research. ii) We tackle the critical problem of avoiding false activation by introducing a novel gestural input concept that leverages a single-finger movement, which stands out from everyday finger motions during holding and manipulating objects. Through a data-driven approach, we also systematically validate the concept’s robustness with different everyday actions. iii) While full sensor coverage on the user’s hand would allow detailed hand-object interaction, minimal instrumentation is desirable for real-world use. This thesis addresses the problem of identifying sparse sensor layouts. We present the first rapid computational method, along with a GUI-based design tool that enables iterative design based on the designer’s high-level requirements. Furthermore, we demonstrate that minimal form-factor devices, like smart rings, can be used to effectively detect microgestures in hands-free and busy scenarios. Overall, the presented findings will serve as both conceptual and technical foundations for enabling interaction with computing devices wherever and whenever users need them.",
    thumb: "images/publications/adwait_phd22.webp",
    modalVideo: "",
    pdf: "https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/34541/1/PhD_Dissertation_Adwait_Sharma.pdf",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@doctoralThesis{Sharma_2022,
  title= {Design and recognition of microgestures for always-available input},
  author= {Sharma, Adwait},
  doi= {http://dx.doi.org/10.22028/D291-38021},
  year= {2022}
}
`
  },

  {
    id: 'p4',
    showInList: true,
    title: "SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-Grained Finger Microgestures",
    authors: "Adwait Sharma, Christina Salchow-Hömmen, Vimal Suresh Mollyn, Aditya Shekhar Nittala, Michael A Hedderich, Marion Koelle, Thomas Seel, Jürgen Steimle",
    venue: "TOCHI 2022",
    type: ["Journal", "Sensing", "AI & Computational Design", "Interaction Techniques"],
    desc: "Computational design tool for optimizing minimal IMU layouts for effective freehand and grasping gesture recognition.",
    fullAbstract: "Gestural interaction with freehands and while grasping an everyday object enables always-available input. To sense such gestures, minimal instrumentation of the user’s hand is desirable. However, the choice of an effective but minimal IMU layout remains challenging, due to the complexity of the multi-factorial space that comprises diverse finger gestures, objects, and grasps. We present SparseIMU, a rapid method for selecting minimal inertial sensor-based layouts for effective gesture recognition. Furthermore, we contribute a computational tool to guide designers with optimal sensor placement. Our approach builds on an extensive microgestures dataset that we collected with a dense network of 17 inertial measurement units (IMUs). We performed a series of analyses, including an evaluation of the entire combinatorial space for freehand and grasping microgestures (393 K layouts), and quantified the performance across different layout choices, revealing new gesture detection opportunities with IMUs. Finally, we demonstrate the versatility of our method with four scenarios.",
    thumb: "images/sparseimu-featured.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3569894",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "https://github.com/HCI-Lab-Saarland/SparseIMU",
    bibtex: `@article{10.1145/3569894,
  author = {Sharma, Adwait and Salchow-H\"{o}mmen, Christina and Mollyn, Vimal Suresh and Nittala, Aditya Shekhar and Hedderich, Michael A. and Koelle, Marion and Seel, Thomas and Steimle, J\"{u}rgen},
  title = {SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-grained Finger Microgestures},
  year = {2023},
  issue_date = {June 2023},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {30},
  number = {3},
  issn = {1073-0516},
  url = {https://doi.org/10.1145/3569894},
  doi = {10.1145/3569894},
  journal = {ACM Trans. Comput.-Hum. Interact.},
  month = jun,
  articleno = {39},
  numpages = {40},
  keywords = {Gesture recognition, hand gestures, sensor placement, imu, objects, design tool}
}

`
  },

  {
    id: 'p3',
    showInList: true,
    title: "Utilizing Interactive Technologies to Encourage Healthy Dietary Behavior",
    authors: "Anuradha Herath, Adwait Sharma, Aditya Shekhar Nittala",
    venue: "MobileHCI Adjunct 2022",
    type: ["Conference", "Sensing", "Interaction Techniques"],
    desc: "Workshop on interactive technologies to promote healthy eating habits.",
    fullAbstract: "Practicing healthy habits in food intake is as important as having a healthy diet for both having a better quality of life as well as in avoiding various health issues. The purpose of this workshop is to provide an environment to discuss and enhance collaborations in the areas of eating detection, eating interruption minimization and healthy dietary feedback. The workshop plans to achieve this goal with design and brainstorming sessions, several invited talks and presentation sessions. In addition to publishing a magazine/ journal article which will provide information about the novel developments in the relevant areas of related research discussed in the workshop, we expect to inspire the participating HCI researchers in potential future collaborations in these areas of research.",
    thumb: "images/publications/healthy_mobilehci22.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3528575.3551427",
    projectUrl: "#",
    slides: "#",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3528575.3551427,
  author = {Herath, Anuradha and Sharma, Adwait and Nittala, Aditya Shekhar},
  title = {Utilizing Interactive Technologies to Encourage Healthy Dietary Behavior},
  year = {2022},
  isbn = {9781450393416},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3528575.3551427},
  doi = {10.1145/3528575.3551427},
  booktitle = {Adjunct Publication of the 24th International Conference on Human-Computer Interaction with Mobile Devices and Services},
  articleno = {5},
  numpages = {5},
  keywords = {Dietary feedback, Dietary monitoring, Eating detection, Human activity recognition, Robust micro-gestures},
  location = {Vancouver, BC, Canada},
  series = {MobileHCI '22}
}

`
  },

  // --- 2021 ---

  {
    id: 'p2',
    showInList: true,
    title: "SoloFinger: Robust Microgestures while Grasping Everyday Objects",
    authors: "Adwait Sharma, Michael A Hedderich, Divyanshu Bhardwaj, Bruno Fruchard, Jess McIntosh, Aditya Shekhar Nittala, Dietrich Klakow, Daniel Ashbrook, Jürgen Steimle",
    venue: "CHI 2021",
    type: ["Conference", "Interaction Techniques", "Sensing"],
    desc: "Easy and rapid-to-perform gestures, which are resilient to false activations.",
    fullAbstract: "Using microgestures, prior work has successfully enabled gestural interactions while holding objects. Yet, these existing methods are prone to false activations caused by natural finger movements while holding or manipulating the object. We address this issue with SoloFinger, a novel concept that allows design of microgestures that are robust against movements that naturally occur during primary activities. Using a data-driven approach, we establish that single-finger movements are rare in everyday hand-object actions and infer a single-finger input technique resilient to false activation. We demonstrate this concept’s robustness using a white-box classifier on a pre-existing dataset comprising 36 everyday hand-object actions. Our findings validate that simple SoloFinger gestures can relieve the need for complex finger configurations or delimiting gestures and that SoloFinger is applicable to diverse hand-object actions. Finally, we demonstrate SoloFinger’s high performance on commodity hardware using random forest classifiers.",
    thumb: "images/publications/solofinger_chi21.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3411764.3445197",
    projectUrl: "#",
    slides: "https://drive.google.com/file/d/1g4p4h84gRd5t08RAOn0Y2YmMg-g8__iU/view?usp=sharing",
    videoUrl: "https://youtu.be/x4jWAIvtivw?si=vGzQOB12RiTf99Bl",
    codeUrl: "https://hci.cs.uni-saarland.de/wp-content/uploads/projects/micro-gestural-input/solofinger/SoloFinger_dataset.zip",
    bibtex: `@inproceedings{10.1145/3411764.3445197,
  author = {Sharma, Adwait and Hedderich, Michael A. and Bhardwaj, Divyanshu and Fruchard, Bruno and McIntosh, Jess and Nittala, Aditya Shekhar and Klakow, Dietrich and Ashbrook, Daniel and Steimle, J\"{u}rgen},
  title = {SoloFinger: Robust Microgestures while Grasping Everyday Objects},
  year = {2021},
  isbn = {9781450380966},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3411764.3445197},
  doi = {10.1145/3411764.3445197},
  booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
  articleno = {744},
  numpages = {15},
  keywords = {microgesture, grasping, false activation, everyday objects},
  location = {Yokohama, Japan},
  series = {CHI '21}
}

`
  },

  {
    id: 'p1',
    showInList: true,
    title: "Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects",
    authors: "Adwait Sharma, Joan Sol Roo, Jürgen Steimle",
    venue: "CHI 2019",
    type: ["Conference", "Interaction Techniques"],
    desc: "Analysis of over 2,400 user-generated microgestures while holding an everyday object.",
    fullAbstract: "Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects.",
    thumb: "images/publications/grasping_chi19.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3290605.3300632",
    projectUrl: "#",
    slides: "https://drive.google.com/file/d/19ZFAyHqiSonQxz51D8qzCH4STwQDXnsK/view?usp=sharing",
    videoUrl: "#",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3290605.3300632,
  author = {Sharma, Adwait and Roo, Joan Sol and Steimle, J\"{u}rgen},
  title = {Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects},
  year = {2019},
  isbn = {9781450359702},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3290605.3300632},
  doi = {10.1145/3290605.3300632},
  booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  pages = {1–13},
  numpages = {13},
  keywords = {elicitation study, gesture recognition, gestures, grasp, microgestures, object, touch},
  location = {Glasgow, Scotland Uk},
  series = {CHI '19}
}

`
  },
  // --- 2017 ---
  {
    id: 'p0',
    showInList: true,
    title: "SmartSleeve: Real-time Sensing of Surface and Deformation Gestures on Flexible, Interactive Textiles, using a Hybrid Gesture Detection Pipeline",
    authors: "Patrick Parzer, Adwait Sharma, Anita Vogl, Jürgen Steimle, Alex Olwal, Michael Haller",
    venue: "UIST 2017",
    type: ["Conference", "Sensing", "Interaction Techniques", "AI & Computational Design"],
    desc: "Wearable textile that can detect 22 surface and deformation gestures in real-time.",
    fullAbstract: "Over the last decades, there have been numerous efforts in wearable computing research to enable interactive textiles. Most work focus, however, on integrating sensors for planar touch gestures, and thus do not fully take advantage of the flexible, deformable and tangible material properties of textile. In this work, we introduce SmartSleeve, a deformable textile sensor, which can sense both surface and deformation gestures in real-time. It expands the gesture vocabulary with a range of expressive interaction techniques, and we explore new opportunities using advanced deformation gestures, such as, Twirl, Twist, Fold, Push and Stretch. We describe our sensor design, hardware implementation and its novel non-rigid connector architecture. We provide a detailed description of our hybrid gesture detection pipeline that uses learning-based algorithms and heuristics to enable real-time gesture detection and tracking. Its modular architecture allows us to derive new gestures through the combination with continuous properties like pressure, location, and direction. Finally, we report on the promising results from our evaluations which demonstrate real-time classification.",
    thumb: "images/smartsleeve-featured.webp",
    modalVideo: "",
    pdf: "https://dl.acm.org/doi/epdf/10.1145/3126594.3126652",
    projectUrl: "#",
    slides: "https://drive.google.com/file/d/1mJgtWjACO0Ccv3cCFkFSUgp8sr_A6x5K/view?usp=sharing",
    videoUrl: "https://youtu.be/PJ-31BQrHmQ",
    codeUrl: "#",
    bibtex: `@inproceedings{10.1145/3126594.3126652,
  author = {Parzer, Patrick and Sharma, Adwait and Vogl, Anita and Steimle, J\"{u}rgen and Olwal, Alex and Haller, Michael},
  title = {SmartSleeve: Real-time Sensing of Surface and Deformation Gestures on Flexible, Interactive Textiles, using a Hybrid Gesture Detection Pipeline},
  year = {2017},
  isbn = {9781450349819},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3126594.3126652},
  doi = {10.1145/3126594.3126652},
  booktitle = {Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
  pages = {565–577},
  numpages = {13},
  keywords = {surface gestures, smart textile, deformation gestures},
  location = {Qu\'{e}bec City, QC, Canada},
  series = {UIST '17}
}



`
  }
];